{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "from google.cloud import aiplatform\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PROJECT_ID=$(gcloud config get-value project)\n",
    "PROJECT_ID = \"bqml-sandbox-396011\"\n",
    "VERTEX_AI_LOCATION = 'europe-west4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=VERTEX_AI_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owerview\n",
    "\n",
    "There are four ways to export BigQueryMl models:\n",
    "1. by using the Google Cloud Console,\n",
    "2. by using `EXPORT MODEL` statement,\n",
    "3. by using `bq extract` command,\n",
    "4. Using API or Client Library.\n",
    "\n",
    "Most of the time the model is saved by default as `TensorfFlow SavedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+--------------------------------+--------+-----------------+\n",
      "|                 Id                  |           Model Type           | Labels |  Creation Time  |\n",
      "+-------------------------------------+--------------------------------+--------+-----------------+\n",
      "| AUTO_KERAS_MODEL                    | TENSORFLOW                     |        | 16 Sep 17:29:09 |\n",
      "| AUTO_ML                             | AUTOML_CLASSIFIER              |        | 10 Sep 13:27:47 |\n",
      "| BASE_LOGISTIC_REGRESSION            | LOGISTIC_REGRESSION            |        | 10 Sep 08:38:52 |\n",
      "| DIMMENSIONALITY_REDUCTION_PCA       | PCA                            |        | 18 Sep 13:22:09 |\n",
      "| DNN                                 | DNN_LINEAR_COMBINED_CLASSIFIER |        | 10 Sep 11:43:48 |\n",
      "| LOGISTIC_REGRESSION_WITH_HP_TUNNING | LOGISTIC_REGRESSION            |        | 10 Sep 11:58:26 |\n",
      "| LOGISTIC_REGRESSION_WITH_PCA        | LOGISTIC_REGRESSION            |        | 18 Sep 13:33:22 |\n",
      "+-------------------------------------+--------------------------------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# list all models\n",
    "!bq ls -m --format=pretty $PROJECT_ID:BQ_ML_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gcs bucket to store models\n",
    "\n",
    "project_id = \"bqml-sandbox-396011\"\n",
    "bucket_name = \"bq-ml-store\"\n",
    "default_storage_class = \"STANDARD\" \n",
    "\n",
    "# Initialize the client\n",
    "client = storage.Client(project=project_id)\n",
    "\n",
    "# Create the bucket with the specified default storage class\n",
    "bucket = client.bucket(bucket_name)\n",
    "bucket.location = \"EU\"\n",
    "bucket.storage_class = default_storage_class\n",
    "    # Try to create the bucket (it will raise an error if it already exists)\n",
    "try:\n",
    "    bucket.create()\n",
    "    print(f\"Bucket '{bucket_name}' created with default storage class '{default_storage_class}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating bucket: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_rafb471f5315eeba_0000018ac65d5eab_1 ... (23s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract --model 'BQ_ML_ID.BASE_LOGISTIC_REGRESSION' gs://bq-ml-store/base-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b29774217648539181f7244fc0e423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    " EXPORT MODEL `BQ_ML_ID.DNN`\n",
    " OPTIONS(URI = 'gs://bq-ml-store/dnn')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "ALTER MODEL BQ_ML_ID.BASE_LOGISTIC_REGRESSION SET OPTIONS (vertex_ai_model_id=\"base_logistic_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Model in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an endpoint\n",
    "\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "        display_name= \"base_logistic_regression\",\n",
    "        project= PROJECT_ID,\n",
    "        location= VERTEX_AI_LOCATION,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy a model\n",
    "model = aiplatform.Model(model_name = \"base_logistic_regression\")\n",
    "model.deploy(\n",
    "    endpoint = endpoint,\n",
    "    deployed_model_display_name = \"base_logistic_regression\",\n",
    "    traffic_percentage = 100, # only one model in the endpoint so it must be 100%\n",
    "    machine_type = \"n1-standard-2\",\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 4,\n",
    "    accelerator_type = None ,\n",
    "    accelerator_count = None ,\n",
    "    sync=True,\n",
    "    )\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample prediction\n",
    "# To TEST !\n",
    "example = {\n",
    "    \"island\": \"Dream\",\n",
    "    \"culmen_length_mm\": 36.6,\n",
    "    \"culmen_depth_mm\": 18.4,\n",
    "    \"flipper_length_mm\": 184.0,\n",
    "    \"body_mass_g\": 3475.0,\n",
    "    \"sex\": \"FEMALE\",\n",
    "}\n",
    "\n",
    "prediction = endpoint.predict([example])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a Model to BigQuery ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models defined and trained outside of the BigQuery ML can be also imported into the service\n",
    "The possible extensions are:\n",
    "1. XGBoost,\n",
    "2. Tensorflow,\n",
    "3. Tensorflow light,\n",
    "4. Open Neural Network Exchange (ONNX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a XGBoost model <br>\n",
    "\n",
    "I tried importing the XGBoost models but the were many errors especially because at the moment the BigQuery ML does not support the current version of XGBoost, but only below 1.5.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Tensorflow model \n",
    "\n",
    "BigQueryMl should work well with Tensorflow because there are both created by Google. <br>\n",
    "Keras is a high-level interface for tensorflow which simplifies building the deep-learning models. <br>\n",
    "AutoKeras is library that perform automatic machine learning using Keras. <br>\n",
    "It was developed by Texas A@M University. <br>\n",
    "Check out the website \"https://autokeras.com and the paper https://jmlr.org/papers/v24/20-1355.html .\n",
    "\n",
    "The training of the model is performed in keras_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://auto_keras_classifier/fingerprint.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://auto_keras_classifier/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://auto_keras_classifier/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://auto_keras_classifier/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "- [4 files][454.7 KiB/454.7 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://auto_keras_classifier/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "- [5 files][607.4 KiB/607.4 KiB]                                                \n",
      "Operation completed over 5 objects/607.4 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Coping the model to gcs\n",
    "# It turns out that you can copy to folder that does not exist and it will be created automatically\n",
    "!gsutil cp -r auto_keras_classifier/* gs://default-credit-clients-2023/auto_keras_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4366d9c45dbf4d30bfdf6906b694e140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL `BQ_ML_ID.AUTO_KERAS_MODEL`\n",
    " OPTIONS(MODEL_TYPE='TENSORFLOW',\n",
    "         MODEL_PATH=\"gs://default-credit-clients-2023/auto_keras_classifier/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+--------------------------------+--------+-----------------+\n",
      "|                 Id                  |           Model Type           | Labels |  Creation Time  |\n",
      "+-------------------------------------+--------------------------------+--------+-----------------+\n",
      "| AUTO_KERAS_MODEL                    | TENSORFLOW                     |        | 16 Sep 17:29:09 |\n",
      "| AUTO_ML                             | AUTOML_CLASSIFIER              |        | 10 Sep 13:27:47 |\n",
      "| BASE_LOGISTIC_REGRESSION            | LOGISTIC_REGRESSION            |        | 10 Sep 08:38:52 |\n",
      "| DNN                                 | DNN_LINEAR_COMBINED_CLASSIFIER |        | 10 Sep 11:43:48 |\n",
      "| LOGISTIC_REGRESSION_WITH_HP_TUNNING | LOGISTIC_REGRESSION            |        | 10 Sep 11:58:26 |\n",
      "+-------------------------------------+--------------------------------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# checking if model was properly imported \n",
    "\n",
    "!PROJECT_ID=$(gcloud config get-value project)\n",
    "!bq ls -m --format=pretty $PROJECT_ID:BQ_ML_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
