{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/python/3.10.8/lib/python3.10/site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Upgrade pip\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autokeras\n",
      "  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from autokeras) (21.3)\n",
      "Collecting tensorflow>=2.8.0 (from autokeras)\n",
      "  Obtaining dependency information for tensorflow>=2.8.0 from https://files.pythonhosted.org/packages/5a/f2/5c2f878c62c8b79c629b11b33516bb55054d7677eba6f56f3a20296b56bd/tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting keras-tuner>=1.1.0 (from autokeras)\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras-nlp>=0.4.0 (from autokeras)\n",
      "  Obtaining dependency information for keras-nlp>=0.4.0 from https://files.pythonhosted.org/packages/13/fc/258d2a78faaacceeaab2be1a64fbf69f77bd56d55758cd4188db3b0f71e3/keras_nlp-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from autokeras) (2.0.3)\n",
      "Collecting keras-core (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for keras-core from https://files.pythonhosted.org/packages/33/18/5280fbfd70485fae8088a2f44647ea0d82c7dc9b80635ae2e7c578f785e0/keras_core-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading keras_core-0.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting absl-py (from keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/python/3.10.8/lib/python3.10/site-packages (from keras-nlp>=0.4.0->autokeras) (1.24.4)\n",
      "Collecting regex (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for regex from https://files.pythonhosted.org/packages/d1/df/460ca6171a8494fcf37af43f52f6fac23e38784bb4a26563f6fa01ef6faf/regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/8d/5f/21a93b2ec205f4b79853ff6e838e3c99064d5dbe85ec6b05967506f14af0/rich-13.5.2-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.5.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tensorflow-text (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-text from https://files.pythonhosted.org/packages/c3/04/01e331424b02c88bce2a71d498fbf2507832b3289f2ac71f466a06e81aee/tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from keras-tuner>=1.1.0->autokeras) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner>=1.1.0->autokeras)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow>=2.8.0->autokeras) (1.57.0)\n",
      "Collecting h5py>=2.9.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/0d/7a/e55589e4093cca1934db5e99644c1c2424a9b3aac104b7f6176605a5eeb7/h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/ea/df/55525e489c43f9dbb6c8ea27d8a567b3dcd18a22f3c45483055f5ca6611d/libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy (from keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow>=2.8.0->autokeras) (4.24.2)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow>=2.8.0->autokeras) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/88/99/8b507a009359fd55e411001acb64a1a8a4f81a26cb6e21c3b75c7fda4ae3/tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from packaging->autokeras) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->autokeras) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->autokeras) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->autokeras) (2023.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.22.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (3.4.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/9b/59/a7c32e3d8d0e546a206e0552a2c04444544f15c1da4a01df8938d20c6ffc/werkzeug-2.3.7-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2023.5.7)\n",
      "Collecting namex (from keras-core->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting dm-tree (from keras-core->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0 (from rich->keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras-nlp>=0.4.0->autokeras) (2.15.1)\n",
      "Collecting tensorflow-hub>=0.8.0 (from tensorflow-text->keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-hub>=0.8.0 from https://files.pythonhosted.org/packages/30/78/9d5292a2b616901bdb075bbf0c777b293f4140bb48108ac2b33fd716c2eb/tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/python/3.10.8/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (4.9)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/python/3.10.8/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.5.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras_nlp-0.6.1-py3-none-any.whl (573 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.5/573.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras_core-0.1.5-py3-none-any.whl (924 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.6/924.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_hub-0.14.0-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.3/90.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, kt-legacy, flatbuffers, dm-tree, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, regex, oauthlib, numpy, mdurl, keras, google-pasta, gast, astunparse, absl-py, tensorflow-hub, requests-oauthlib, opt-einsum, markdown-it-py, keras-tuner, h5py, rich, google-auth-oauthlib, tensorboard, keras-core, tensorflow, tensorflow-text, keras-nlp, autokeras\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.10 are installed in '/opt/python/3.10.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown-it is installed in '/opt/python/3.10.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/opt/python/3.10.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/opt/python/3.10.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/opt/python/3.10.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 astunparse-1.6.3 autokeras-1.1.0 dm-tree-0.1.8 flatbuffers-23.5.26 gast-0.4.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 h5py-3.9.0 keras-2.13.1 keras-core-0.1.5 keras-nlp-0.6.1 keras-tuner-1.3.5 kt-legacy-1.0.5 libclang-16.0.6 markdown-it-py-3.0.0 mdurl-0.1.2 namex-0.0.7 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 regex-2023.8.8 requests-oauthlib-1.3.1 rich-13.5.2 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-hub-0.14.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-text-2.13.0 termcolor-2.3.0 typing-extensions-4.5.0 werkzeug-2.3.7 wrapt-1.15.0\n",
      "Requirement already satisfied: tensorflow==2.13.* in /opt/python/3.10.8/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.13.*) (1.57.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.13.*) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (4.24.2)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.13.*) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow==2.13.*) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorflow==2.13.*) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.*) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.*) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.*) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.*) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.*) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.*) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.*) (2.3.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from packaging->tensorflow==2.13.*) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/python/3.10.8/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/python/3.10.8/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/codespace/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/python/3.10.8/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/python/3.10.8/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.*) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --user google-cloud-bigquery==3.4.1\n",
    "#!pip install --user pandas\n",
    "#!pip install google-cloud-bigquery\n",
    "#!pip install google-cloud-bigquery-storage\n",
    "#!pip install google-cloud-storage\n",
    "#!pip install pyarrow\n",
    "#!pip install db-dtypes\n",
    "#!pip install tqdm\n",
    "#!pip install matplotlib\n",
    "#!pip install ipywidgets\n",
    "#!pip install ipywidgets\n",
    "#!pip install google-cloud-aiplatform\n",
    "#!pip install numpy\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install autokeras\n",
    "!pip install scikit-learn \n",
    "! pip install tensorflow==2.13.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PROJECT_ID=$(gcloud config get-value project)\n",
    "PROJECT_ID = \"bqml-sandbox-396011\"\n",
    "VERTEX_AI_LOCATION = 'europe-west4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=VERTEX_AI_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owerview\n",
    "\n",
    "There are four ways to export BigQueryMl models:\n",
    "1. by using the Google Cloud Console,\n",
    "2. by using `EXPORT MODEL` statement,\n",
    "3. by using `bq extract` command,\n",
    "4. Using API or Client Library.\n",
    "\n",
    "Most of the time the model is saved by default as `TensorfFlow SavedModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to BigQuery! This script will walk you through the \n",
      "process of initializing your .bigqueryrc configuration file.\n",
      "\n",
      "First, we need to set up your credentials if they do not \n",
      "already exist.\n",
      "\n",
      "Setting project_id bqml-sandbox-396011 as the default.\n",
      "\n",
      "BigQuery configuration complete! Type \"bq\" to get started.\n",
      "\n",
      "+--------------------------+--------------------------------+--------+-----------------+\n",
      "|            Id            |           Model Type           | Labels |  Creation Time  |\n",
      "+--------------------------+--------------------------------+--------+-----------------+\n",
      "| BASE_LOGISTIC_REGRESSION | LOGISTIC_REGRESSION            |        | 10 Sep 08:38:52 |\n",
      "| DNN                      | DNN_LINEAR_COMBINED_CLASSIFIER |        | 10 Sep 11:43:48 |\n",
      "+--------------------------+--------------------------------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# list all models\n",
    "!bq ls -m --format=pretty $PROJECT_ID:BQ_ML_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5043/2528192649.py:12: DeprecationWarning: Assignment to 'Bucket.location' is deprecated, as it is only valid before the bucket is created. Instead, pass the location to `Bucket.create`.\n",
      "  bucket.location = \"EU\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'bq-ml-store' created with default storage class 'STANDARD'.\n"
     ]
    }
   ],
   "source": [
    "# Create gcs bucket to store models\n",
    "\n",
    "project_id = \"bqml-sandbox-396011\"\n",
    "bucket_name = \"bq-ml-store\"\n",
    "default_storage_class = \"STANDARD\" \n",
    "\n",
    "# Initialize the client\n",
    "client = storage.Client(project=project_id)\n",
    "\n",
    "# Create the bucket with the specified default storage class\n",
    "bucket = client.bucket(bucket_name)\n",
    "bucket.location = \"EU\"\n",
    "bucket.storage_class = default_storage_class\n",
    "    # Try to create the bucket (it will raise an error if it already exists)\n",
    "try:\n",
    "    bucket.create()\n",
    "    print(f\"Bucket '{bucket_name}' created with default storage class '{default_storage_class}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating bucket: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r53868589930e1046_0000018a7f0057a2_1 ... (33s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract --model 'BQ_ML_ID.BASE_LOGISTIC_REGRESSION' gs://bq-ml-store/base-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c432a9d5cbe4552bf77fc628bdc830a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    " EXPORT MODEL `BQ_ML_ID.DNN`\n",
    " OPTIONS(URI = 'gs://bq-ml-store/dnn')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8418f1543dd4d9f90792d457589dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "ALTER MODEL BQ_ML_ID.BASE_LOGISTIC_REGRESSION SET OPTIONS (vertex_ai_model_id=\"base_logistic_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Model in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/115333740492/locations/europe-west4/endpoints/8224984692508590080/operations/4462031765648703488\n",
      "Endpoint created. Resource name: projects/115333740492/locations/europe-west4/endpoints/8224984692508590080\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/115333740492/locations/europe-west4/endpoints/8224984692508590080')\n"
     ]
    }
   ],
   "source": [
    "# create an endpoint\n",
    "\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "        display_name= \"base_logistic_regression\",\n",
    "        project= PROJECT_ID,\n",
    "        location= VERTEX_AI_LOCATION,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/115333740492/locations/europe-west4/endpoints/8224984692508590080\n",
      "Deploy Endpoint model backing LRO: projects/115333740492/locations/europe-west4/endpoints/8224984692508590080/operations/3963821056870842368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint model deployed. Resource name: projects/115333740492/locations/europe-west4/endpoints/8224984692508590080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f66b34ce710> \n",
       "resource name: projects/115333740492/locations/europe-west4/endpoints/8224984692508590080"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deploy a model\n",
    "model = aiplatform.Model(model_name = \"base_logistic_regression\")\n",
    "model.deploy(\n",
    "    endpoint = endpoint,\n",
    "    deployed_model_display_name = \"base_logistic_regression\",\n",
    "    traffic_percentage = 100, # only one model in the endpoint so it must be 100%\n",
    "    machine_type = \"n1-standard-2\",\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 4,\n",
    "    accelerator_type = None ,\n",
    "    accelerator_count = None ,\n",
    "    sync=True,\n",
    "    )\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample prediction\n",
    "# To TEST !\n",
    "example = {\n",
    "    \"island\": \"Dream\",\n",
    "    \"culmen_length_mm\": 36.6,\n",
    "    \"culmen_depth_mm\": 18.4,\n",
    "    \"flipper_length_mm\": 184.0,\n",
    "    \"body_mass_g\": 3475.0,\n",
    "    \"sex\": \"FEMALE\",\n",
    "}\n",
    "\n",
    "prediction = endpoint.predict([example])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a Model to BigQuery ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models defined and trained outside of the BigQuery ML can be also imported into the service\n",
    "The possible extensions are:\n",
    "1. XGBoost,\n",
    "2. Tensorflow,\n",
    "3. Tensorflow light,\n",
    "4. Open Neural Network Exchange (ONNX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a XGBoost model <br>\n",
    "\n",
    "I tried importing the XGBoost models but the were many errors especially because at the moment the BigQuery ML does not support the current version of XGBoost, but only below 1.5.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Tensorflow model \n",
    "\n",
    "BigQueryMl should work well with Tensorflow because there are both created by Google. <br>\n",
    "Keras is a high-level interface for tensorflow which simplifies building the deep-learning models. <br>\n",
    "AutoKeras is library that perform automatic machine learning using Keras. <br>\n",
    "It was developed by Texas A@M University. <br>\n",
    "Check out the website \"https://autokeras.com and the paper https://jmlr.org/papers/v24/20-1355.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/default-of-credit-card-clients.csv\",delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"default payment next month\"]\n",
    "X = data.drop([\"default payment next month\",\"ID\",\"MARRIAGE\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_keras_classifier = ak.StructuredDataClassifier(\n",
    "    overwrite=True, max_trials=3\n",
    ")  # It tries 3 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.8116817474365234\n",
      "\n",
      "Best val_accuracy So Far: 0.8116817474365234\n",
      "Total elapsed time: 00h 01m 01s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "629/629 [==============================] - 3s 3ms/step - loss: 0.4661 - accuracy: 0.8110\n",
      "Epoch 2/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8176\n",
      "Epoch 3/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4385 - accuracy: 0.8185\n",
      "Epoch 4/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4320 - accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.8209\n",
      "Epoch 7/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.8218\n",
      "Epoch 8/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8224\n",
      "Epoch 9/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.8238\n",
      "Epoch 10/10\n",
      "629/629 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8239\n",
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f611cbb6a40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_keras_classifier.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.functional.Functional'>\n",
      "INFO:tensorflow:Assets written to: auto_keras_classifier/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: auto_keras_classifier/assets\n"
     ]
    }
   ],
   "source": [
    "# export model\n",
    "model = auto_keras_classifier.export_model()\n",
    "\n",
    "print(type(model))  \n",
    "\n",
    "try:\n",
    "    model.save(\"auto_keras_classifier\", save_format=\"tf\")\n",
    "except Exception:\n",
    "    print(\"unable to save the model in tensorflow format, try legacy h5 format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://auto_keras_classifier/fingerprint.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://auto_keras_classifier/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://auto_keras_classifier/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://auto_keras_classifier/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "- [4 files][454.7 KiB/454.7 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://auto_keras_classifier/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "- [5 files][607.4 KiB/607.4 KiB]                                                \n",
      "Operation completed over 5 objects/607.4 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Coping the model to gcs\n",
    "# It turns out that you can copy to folder that does not exist and it will be created automatically\n",
    "!gsutil cp -r auto_keras_classifier/* gs://default-credit-clients-2023/auto_keras_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4366d9c45dbf4d30bfdf6906b694e140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL `BQ_ML_ID.AUTO_KERAS_MODEL`\n",
    " OPTIONS(MODEL_TYPE='TENSORFLOW',\n",
    "         MODEL_PATH=\"gs://default-credit-clients-2023/auto_keras_classifier/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+--------------------------------+--------+-----------------+\n",
      "|                 Id                  |           Model Type           | Labels |  Creation Time  |\n",
      "+-------------------------------------+--------------------------------+--------+-----------------+\n",
      "| AUTO_KERAS_MODEL                    | TENSORFLOW                     |        | 16 Sep 17:29:09 |\n",
      "| AUTO_ML                             | AUTOML_CLASSIFIER              |        | 10 Sep 13:27:47 |\n",
      "| BASE_LOGISTIC_REGRESSION            | LOGISTIC_REGRESSION            |        | 10 Sep 08:38:52 |\n",
      "| DNN                                 | DNN_LINEAR_COMBINED_CLASSIFIER |        | 10 Sep 11:43:48 |\n",
      "| LOGISTIC_REGRESSION_WITH_HP_TUNNING | LOGISTIC_REGRESSION            |        | 10 Sep 11:58:26 |\n",
      "+-------------------------------------+--------------------------------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# checking if model was properly imported \n",
    "\n",
    "!PROJECT_ID=$(gcloud config get-value project)\n",
    "!bq ls -m --format=pretty $PROJECT_ID:BQ_ML_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
