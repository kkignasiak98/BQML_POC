{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "from google.cloud import aiplatform\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PROJECT_ID=$(gcloud config get-value project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null # to supress any error messages\n",
    "PROJECT_ID = shell_output[0]\n",
    "VERTEX_AI_LOCATION = 'europe-west4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID, location = VERTEX_AI_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "There are four ways to export BigQueryMl models:\n",
    "1. by using the Google Cloud Console,\n",
    "2. by using `EXPORT MODEL` statement,\n",
    "3. by using `bq extract` command,\n",
    "4. Using API or Client Library.\n",
    "\n",
    "Most of the time the model is saved by default as `TensorfFlow SavedModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the model to GCS bucket\n",
    "By using console and BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all models\n",
    "!bq ls -m --format=pretty $PROJECT_ID:BQ_ML_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gcs bucket to store models\n",
    "\n",
    "bucket_name = \"bq-ml-store\"\n",
    "default_storage_class = \"STANDARD\" \n",
    "\n",
    "# Initialize the client\n",
    "client = storage.Client(project = PROJECT_ID)\n",
    "\n",
    "# Create the bucket with the specified default storage class\n",
    "bucket = client.bucket(bucket_name)\n",
    "bucket.location = \"EU\"\n",
    "bucket.storage_class = default_storage_class\n",
    "    # Try to create the bucket (it will raise an error if it already exists)\n",
    "try:\n",
    "    bucket.create()\n",
    "    print(f\"Bucket '{bucket_name}' created with default storage class '{default_storage_class}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating bucket: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq extract --model 'BQ_ML_ID.BASE_LOGISTIC_REGRESSION' gs://bq-ml-store/base-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    " EXPORT MODEL `BQ_ML_ID.DNN`\n",
    " OPTIONS(URI = 'gs://bq-ml-store/dnn')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "ALTER MODEL BQ_ML_ID.BASE_LOGISTIC_REGRESSION SET OPTIONS (vertex_ai_model_id = \"base_logistic_regression\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Model in Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an endpoint\n",
    "\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = \"base_logistic_regression\",\n",
    "        project = PROJECT_ID,\n",
    "        location = VERTEX_AI_LOCATION,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy a model\n",
    "model = aiplatform.Model(model_name = \"base_logistic_regression\")\n",
    "model.deploy(\n",
    "    endpoint = endpoint,\n",
    "    deployed_model_display_name = \"base_logistic_regression\",\n",
    "    traffic_percentage = 100, # only one model in the endpoint so it must be 100%\n",
    "    machine_type = \"n1-standard-2\",\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 4,\n",
    "    accelerator_type = None ,\n",
    "    accelerator_count = None ,\n",
    "    sync = True,\n",
    "    )\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai endpoints list --region=europe-west4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint('8224984692508590080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[{'card_default_probs': [0.9897584087370261, 0.01024159126297386], 'predicted_card_default': ['1'], 'card_default_values': ['1', '0']}], deployed_model_id='5557499114779836416', model_version_id='1', model_resource_name='projects/115333740492/locations/europe-west4/models/base_logistic_regression', explanations=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample prediction\n",
    "example = {\n",
    "    \"LIMIT_BAL\": 20000,\n",
    "    \"SEX\": \"2\",\n",
    "    \"EDUCATION\": \"2\",\n",
    "    \"AGE\": 24,\n",
    "\n",
    "    \"PAY_0\": \"-2\",\n",
    "    \"PAY_2\": \"2\",\n",
    "    \"PAY_3\": \"-1\",\n",
    "    \"PAY_4\": \"-1\",\n",
    "    \"PAY_5\": \"-1\",\n",
    "    \"PAY_6\": \"-1\",\n",
    "\n",
    "    \"BILL_AMT1\": 0,\n",
    "    \"BILL_AMT2\": 0,\n",
    "    \"BILL_AMT3\": 0,\n",
    "    \"BILL_AMT4\": 0,\n",
    "    \"BILL_AMT5\": 0,\n",
    "    \"BILL_AMT6\": 0,\n",
    "\n",
    "    \"PAY_AMT1\": 0,\n",
    "    \"PAY_AMT2\": 0,\n",
    "    \"PAY_AMT3\": 0,\n",
    "    \"PAY_AMT4\": 0,\n",
    "    \"PAY_AMT5\": 0,\n",
    "    \"PAY_AMT6\": 0,\n",
    "}\n",
    "prediction = endpoint.predict([example])\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a Model to BigQuery ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models defined and trained outside of the BigQuery ML can be also imported into the service.\n",
    "The possible extensions are:\n",
    "1. XGBoost,\n",
    "2. Tensorflow,\n",
    "3. Tensorflow light,\n",
    "4. Open Neural Network Exchange (ONNX).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a XGBoost model <br>\n",
    "\n",
    "I tried importing the XGBoost models but the were many errors especially because at the moment the BigQuery ML does not support the current version of XGBoost, but only below 1.5.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Tensorflow model \n",
    "\n",
    "BigQueryMl should work well with Tensorflow because they are both created by Google. <br>\n",
    "Keras is a high-level interface for tensorflow which simplifies building the deep-learning models. <br>\n",
    "AutoKeras is a library that performs automatic machine learning using Keras. <br>\n",
    "It was developed by Texas A@M University. <br>\n",
    "Check out the website \"https://autokeras.com and the paper https://jmlr.org/papers/v24/20-1355.html .\n",
    "\n",
    "The training of the model is performed in `keras_model.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coping the model to gcs\n",
    "# It turns out that you can copy to folder that does not exist and it will be created automatically\n",
    "!gsutil cp -r auto_keras_classifier/* gs://default-credit-clients-2023/auto_keras_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL `BQ_ML_ID.AUTO_KERAS_MODEL`\n",
    " OPTIONS(MODEL_TYPE='TENSORFLOW',\n",
    "         MODEL_PATH=\"gs://default-credit-clients-2023/auto_keras_classifier/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if model was properly imported \n",
    "!bq ls -m --format=pretty $PROJECT_ID:BQ_ML_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
